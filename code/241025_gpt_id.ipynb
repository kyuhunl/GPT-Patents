{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17bbddf-e259-41cd-9150-4b371ee69ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5006c8aa-6c99-41cd-925c-8536ac5c2a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open g_cpc_title.tsv.zip to a dataframe without extracting    \n",
    "with zipfile.ZipFile('g_cpc_title.tsv.zip', 'r') as zip_ref:\n",
    "    cpc_title = pd.read_csv(zip_ref.open('g_cpc_title.tsv'), sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dae3920-ae45-4448-a8ee-ba0c6e4eb482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open g_cpc_current.tsv.zip to a dataframe without extracting\n",
    "with zipfile.ZipFile('g_cpc_current.tsv.zip', 'r') as zip_ref:\n",
    "    cpc_current = pd.read_csv(zip_ref.open('g_cpc_current.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062eee13-d8f1-467e-bdd7-fea6dccdc8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('citations_partmerged.csv.zip', 'r') as zip_ref:\n",
    "    citations = pd.read_csv(zip_ref.open('citations_partmerged.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a8bf65-2b63-4ef1-b2cb-8005fb456890",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = citations.drop(columns={'Unnamed: 0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdf7ec9-0951-4ff3-b2a0-0e4e610ef1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc_current['patent_id'] = cpc_current['patent_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1846e844-d671-4fbe-bbe6-25f14611cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = citations.merge(cpc_current[['patent_id','cpc_subclass']], left_on='citation_patent_id', right_on='patent_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8013bf2-277d-43b6-9ae3-dbe0a82d2041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of each chunk\n",
    "chunk_size = 500000  # Adjust based on memory limits\n",
    "chunks = []\n",
    "\n",
    "# Split 'citations' into chunks\n",
    "for i in range(0, len(citations), chunk_size):\n",
    "    chunk = citations.iloc[i:i + chunk_size]\n",
    "    \n",
    "    # Perform the merge on each chunk\n",
    "    merged_chunk = chunk.merge(cpc_current[['patent_id', 'cpc_subclass']], \n",
    "                               left_on='citation_patent_id', \n",
    "                               right_on='patent_id', \n",
    "                               how='inner')\n",
    "    \n",
    "    # Drop the extra 'patent_id' column from 'cpc_current' after the merge\n",
    "    merged_chunk = merged_chunk.drop(columns=['patent_id_y']).rename(columns={'patent_id_x':'patent_id','cpc_subclass':'cited_subclass'})\n",
    "    \n",
    "    # Perform groupby operations (example: counting occurrences of each subclass)\n",
    "    grouped_chunk = merged_chunk.groupby(['citation_patent_id', 'cpc_subclass']).size().reset_index(name='count')\n",
    "    \n",
    "    # Append the result to the list\n",
    "    chunks.append(grouped_chunk)\n",
    "\n",
    "# Concatenate all chunks back into a single DataFrame\n",
    "final_result = pd.concat(chunks, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731dd4d2-2ed3-49f2-b77e-88a6ee37b736",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the size of each chunk\n",
    "chunk_size = 500000  # Adjust based on memory limits\n",
    "\n",
    "# Define a counter for file naming and progress tracking\n",
    "file_counter = 1\n",
    "\n",
    "# Split 'citations' into chunks\n",
    "for i in range(0, len(citations), chunk_size):\n",
    "    chunk = citations.iloc[i:i + chunk_size]\n",
    "    \n",
    "    # Perform the merge on each chunk\n",
    "    merged_chunk = chunk.merge(cpc_current[['patent_id', 'cpc_subclass']], \n",
    "                               left_on='citation_patent_id', \n",
    "                               right_on='patent_id', \n",
    "                               how='inner')\n",
    "    \n",
    "    # Drop the extra 'patent_id' column from 'cpc_current' after the merge\n",
    "    merged_chunk = merged_chunk.drop(columns=['patent_id_y']).rename(columns={'patent_id_x':'patent_id','cpc_subclass':'cited_subclass'})\n",
    "    \n",
    "    # Perform groupby operations (example: counting occurrences of each subclass)\n",
    "    grouped_chunk = merged_chunk.groupby(['citing_subclass', 'cited_subclass']).size().reset_index(name='count')\n",
    "    \n",
    "    # Save the grouped chunk to a file\n",
    "    file_name = f'grouped_chunk_{file_counter}.csv'\n",
    "    grouped_chunk.to_csv(file_name, index=False)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Processed chunk {file_counter}, saved as {file_name}\")\n",
    "    \n",
    "    # Increment the counter for the next file\n",
    "    file_counter += 1\n",
    "\n",
    "print(\"All chunks processed and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c55935-4426-4209-a84b-69122688e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470c99bd-7657-4f5a-b747-68395935a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('grouped_chunk_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247a4aec-29f0-43a5-b805-6f569754fd59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged = pd.DataFrame()\n",
    "for i in range(1,590):\n",
    "    file_name = f'grouped_chunk_{i}.csv'\n",
    "    chunk = pd.read_csv(file_name)\n",
    "    merged = pd.concat([merged,chunk], ignore_index=True)\n",
    "    merged = merged.groupby(['citing_subclass','cited_subclass'], as_index=False)['count'].sum()\n",
    "    print(f'file {i} merged')\n",
    "\n",
    "merged.to_csv('cpc_cross_citation.csv', index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c3747-980d-4ac9-8d22-d45913a1a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4498748b-cc37-449f-81de-16ba412f8329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(x):\n",
    "    return 1-sum(x**2)/sum(x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84476776-a303-43db-8d8e-9ae79559b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "hhi(np.array([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95059d83-5a38-47c2-977e-a4ae9b4462e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subclass_generality = merged.groupby('cited_subclass')['count'].apply(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a0948-69fd-4661-a7d9-470d3d55497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subclass_generality = subclass_generality.reset_index().rename(columns={'cited_subclass':'subclass','count':'generality'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6638ef16-92c8-46e6-9a6a-66f610b6fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "subclass_generality = subclass_generality.sort_values('generality', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc272e6-8727-406b-bfbe-3b9685d4e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subclass_generality[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218d633e-546f-4d50-8f32-3b4bea820225",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log(subclass_generality['generality']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a64b8e8-8a57-435f-a04a-e091bdcc464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(cpc_current[['patent_id', 'cpc_subclass']], \n",
    "                               left_on='citation_patent_id', \n",
    "                               right_on='patent_id', \n",
    "                               how='inner').drop(columns=['patent_id_y']).rename(columns={'patent_id_x':'patent_id','cpc_subclass':'cited_subclass'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044cc1bd-dd88-48f7-97da-11219b76f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby(['citing_subclass','cited_subclass']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eca8ed-2fc5-4d62-a135-d0e2cbd0d9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "large",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
