{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPA analysis\n",
    "\n",
    "Example #1: PCR (Kary Mullis, US4683202: Hall of Fame, Kelly et al. significant patents)\n",
    "\n",
    "Plan: collect all patents with CPC class C12Q1/686 - Polymerase chain reaction [PCR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the zip file\n",
    "with zipfile.ZipFile('g_cpc_current.tsv.zip', 'r') as zip_ref:\n",
    "    # extract the .tsv file as a pandas dataframe\n",
    "    with zip_ref.open('g_cpc_current.tsv') as file:\n",
    "        df = pd.read_csv(file, sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr_patents = df[df['cpc_group']=='C12Q1/686']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr_patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr_patent_ids = pcr_patents['patent_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the zip file\n",
    "with zipfile.ZipFile('g_us_patent_citation.tsv.zip', 'r') as zip_ref:\n",
    "    # extract the .tsv file as a pandas dataframe\n",
    "    with zip_ref.open('g_us_patent_citation.tsv') as file:\n",
    "        citations = pd.read_csv(file, sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations['patent_id'] = citations['patent_id'].astype(str)\n",
    "citations['citation_patent_id'] = citations['citation_patent_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to string list\n",
    "pcr_patent_ids = [str(x) for x in pcr_patent_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr_citations = citations[(citations['patent_id'].isin(pcr_patent_ids)) | (citations['citation_patent_id'].isin(pcr_patent_ids))]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr_citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr_citations.to_csv('pcr_citations.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr_patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr_citations_between = pcr_citations[pcr_citations['patent_id'].isin(pcr_patent_ids) & pcr_citations['citation_patent_id'].isin(pcr_patent_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr_citations_between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(pcr_citations_between, 'patent_id', 'citation_patent_id', create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main path analysis\n",
    "source_nodes = [n for n in G.nodes() if G.in_degree(n) == 0]\n",
    "sink_nodes = [n for n in G.nodes() if G.out_degree(n) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {}\n",
    "for source in source_nodes:\n",
    "    for sink in sink_nodes:\n",
    "        try:\n",
    "            # Find all paths between source and sink\n",
    "            paths = list(nx.all_simple_paths(G, source, sink))\n",
    "            \n",
    "            # Update weights for each edge in each path\n",
    "            for path in paths:\n",
    "                for i in range(len(path)-1):\n",
    "                    edge = (path[i], path[i+1])\n",
    "                    weights[edge] = weights.get(edge, 0) + 1\n",
    "        except nx.NetworkXNoPath:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def conduct_mpa(citation_data, weight_method='spc'):\n",
    "    \"\"\"\n",
    "    Conduct Main Path Analysis on patent citation data.\n",
    "    \n",
    "    Parameters:\n",
    "    citation_data (pd.DataFrame): DataFrame with columns 'citing_patent', 'cited_patent'\n",
    "    weight_method (str): 'spc' for Search Path Count (default)\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (main_path_edges, edge_weights, path_significance)\n",
    "    \"\"\"\n",
    "    # Create directed graph\n",
    "    G = nx.DiGraph()\n",
    "    for _, row in citation_data.iterrows():\n",
    "        G.add_edge(row['citing_patent'], row['cited_patent'])\n",
    "    \n",
    "    # Identify source and sink nodes\n",
    "    source_nodes = [n for n in G.nodes() if G.in_degree(n) == 0]\n",
    "    sink_nodes = [n for n in G.nodes() if G.out_degree(n) == 0]\n",
    "    \n",
    "    # Calculate traversal weights using SPC\n",
    "    weights = {}\n",
    "    for source in source_nodes:\n",
    "        for sink in sink_nodes:\n",
    "            try:\n",
    "                # Find all paths between source and sink\n",
    "                paths = list(nx.all_simple_paths(G, source, sink))\n",
    "                \n",
    "                # Update weights for each edge in each path\n",
    "                for path in paths:\n",
    "                    for i in range(len(path)-1):\n",
    "                        edge = (path[i], path[i+1])\n",
    "                        weights[edge] = weights.get(edge, 0) + 1\n",
    "            except nx.NetworkXNoPath:\n",
    "                continue\n",
    "    \n",
    "    # Normalize weights\n",
    "    if weights:\n",
    "        max_weight = max(weights.values())\n",
    "        weights = {k: v/max_weight for k, v in weights.items()}\n",
    "    \n",
    "    # Find main path\n",
    "    main_path_edges = set()\n",
    "    \n",
    "    # Transform weights for shortest path calculation\n",
    "    # (higher traversal weight = shorter path)\n",
    "    transformed_weights = {edge: 1 - weight \n",
    "                         for edge, weight in weights.items()}\n",
    "    \n",
    "    # Find paths between all sources and sinks\n",
    "    for source in source_nodes:\n",
    "        for sink in sink_nodes:\n",
    "            try:\n",
    "                path = nx.shortest_path(G, source, sink, \n",
    "                                      weight=lambda u, v, d: transformed_weights[(u, v)])\n",
    "                \n",
    "                # Add edges from path to main path\n",
    "                for i in range(len(path)-1):\n",
    "                    main_path_edges.add((path[i], path[i+1]))\n",
    "            except nx.NetworkXNoPath:\n",
    "                continue\n",
    "    \n",
    "    # Calculate path significance\n",
    "    if main_path_edges:\n",
    "        path_significance = sum(weights[edge] \n",
    "                              for edge in main_path_edges) / len(main_path_edges)\n",
    "    else:\n",
    "        path_significance = 0\n",
    "        \n",
    "    return main_path_edges, weights, path_significance\n",
    "\n",
    "def analyze_pcr_patents(patent_data, citation_data):\n",
    "    \"\"\"\n",
    "    Analyze PCR patent dataset using MPA.\n",
    "    \n",
    "    Parameters:\n",
    "    patent_data (pd.DataFrame): DataFrame with patent information\n",
    "    citation_data (pd.DataFrame): DataFrame with citation relationships\n",
    "    \n",
    "    Returns:\n",
    "    dict: Analysis results\n",
    "    \"\"\"\n",
    "    # Conduct MPA\n",
    "    main_path, weights, significance = conduct_mpa(citation_data)\n",
    "    \n",
    "    # Analyze main path\n",
    "    main_path_patents = set([p for edge in main_path for p in edge])\n",
    "    \n",
    "    # Get chronological order of main path patents\n",
    "    main_path_info = (patent_data[patent_data['patent_id'].isin(main_path_patents)]\n",
    "                     .sort_values('grant_date'))\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    results = {\n",
    "        'main_path_edges': main_path,\n",
    "        'edge_weights': weights,\n",
    "        'path_significance': significance,\n",
    "        'num_main_path_patents': len(main_path_patents),\n",
    "        'chronological_path': main_path_info['patent_id'].tolist(),\n",
    "        'date_range': (main_path_info['grant_date'].min(),\n",
    "                      main_path_info['grant_date'].max())\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example data format\n",
    "    patent_data = pd.DataFrame({\n",
    "        'patent_id': ['P1', 'P2', 'P3', 'P4', 'P5'],\n",
    "        'grant_date': ['1987-01-01', '1988-01-01', '1989-01-01', \n",
    "                      '1990-01-01', '1991-01-01']\n",
    "    })\n",
    "    \n",
    "    citation_data = pd.DataFrame({\n",
    "        'citing_patent': ['P2', 'P3', 'P3', 'P4', 'P5'],\n",
    "        'cited_patent': ['P1', 'P1', 'P2', 'P3', 'P3']\n",
    "    })\n",
    "    \n",
    "    # Run analysis\n",
    "    results = analyze_pcr_patents(patent_data, citation_data)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Main Path Edges:\", results['main_path_edges'])\n",
    "    print(\"Path Significance:\", results['path_significance'])\n",
    "    print(\"Chronological Development:\", results['chronological_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
